{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import os\n",
    "import gzip\n",
    "\n",
    "import similarityregression.PairwiseAlignment as pwsaln\n",
    "import similarityregression.AlignmentTools as alntools\n",
    "import similarityregression.PredictSimilarity as srpred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook describes an example of how to parse protein sequences from CisBP into a form that can be used for Similarity Regression (training and scoring). \n",
    "\n",
    "# Parse CisBP Data\n",
    "Source data: 5 Homeodomain PBM experiments from CisBP (http://cisbp.ccbr.utoronto.ca/)\n",
    "\n",
    "## Read E-scores and calculate motif similarity (E-Score Overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "escores = pd.read_csv('HomeodomainData/EScore.txt', index_col=0, delimiter='\\t')\n",
    "escores.columns = [x.split(':')[0] for x in escores.columns] #Relabel by moits\n",
    "escores = escores.groupby(by=escores.columns, axis=1).mean() #Average E-scores for replicates\n",
    "\n",
    "#Calculate E-score Overlaps\n",
    "Escorethresh = 0.45\n",
    "EScoreOverlaps = {}\n",
    "\n",
    "MIDs = list(escores.columns)\n",
    "MIDs.sort()\n",
    "for x,y in itertools.combinations(MIDs, 2):\n",
    "    #print x, y\n",
    "    maxN = max(len(set(escores[escores[x] >= Escorethresh][x].index)), len(set(escores[escores[y] >= Escorethresh][y].index)))\n",
    "    x_maxN = set(escores[x].sort_values(ascending = False).iloc[:maxN].index)\n",
    "    y_maxN = set(escores[y].sort_values(ascending = False).iloc[:maxN].index)\n",
    "    escoreoverlap = 1.0*len(x_maxN.intersection(y_maxN))/maxN\n",
    "    #print escoreoverlap, len(x_maxN.intersection(y_maxN)), maxN\n",
    "    EScoreOverlaps[(x,y)] = escoreoverlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF / Protein Information \n",
    "### Parse Protein Information to reference DBD alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins = pd.read_csv('HomeodomainData/prot_seq.txt', index_col=0, delimiter='\\t')\n",
    "\n",
    "motifs = []\n",
    "with open('HomeodomainData/TF_Information.txt', 'r') as infile:\n",
    "    h = infile.readline().strip().split('\\t')\n",
    "    for line in infile:\n",
    "        line = line.strip().split('\\t')\n",
    "        data = line[:6]\n",
    "        mids = line[6:]\n",
    "        mids = [x[:-1] for x in mids]\n",
    "        for mid in mids:\n",
    "            motifs.append([mid] + data)\n",
    "motifs = pd.DataFrame(motifs, columns=[h[-1]] + h[:-1])\n",
    "motifs.set_index('Motif_ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBDseqs = set()\n",
    "for x in proteins['DBD_seqs']:\n",
    "    x = x.split(',') #in cases of multiple DBDs\n",
    "    for seq in x:\n",
    "        DBDseqs.add(seq)\n",
    "        \n",
    "#Write DBDseqs to fasta\n",
    "with open('HDSeqs.fa', 'w') as outfile:\n",
    "    for DBDseq in DBDseqs:\n",
    "        outfile.write('>' + DBDseq + '\\n' + DBDseq + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align to Pfam HMM\n",
    "\n",
    "Source: [https://www.ebi.ac.uk/interpro/entry/pfam/PF00046](https://web.archive.org/web/20190619115817/https://pfam.xfam.org/family/PF00046/hmm) (Wayback Machine link)\n",
    "\n",
    "```bash\n",
    "# from within the `Examples` subdirectory\n",
    "RunAPHID.py HomeodomainData/Homeodomain.hmm HDSeqs.fa semiglobal\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read results into dictionary that maps the DBD sequence to its reference alignment\n",
    "DBDseqs = {} #Actual DBDseq : Reference Alignment \n",
    "for seq, aln in alntools.FastaIter(fileloc='DBDMatchPos_aphid/HDSeqs.matchpos_semiglobal.fa'):\n",
    "    DBDseqs[seq] = aln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Motif Sequences and Alignments to Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MotifSequences = {} # MID: [DBD Sequences]\n",
    "for mid in MIDs:\n",
    "    #print mid\n",
    "    minfo = motifs.loc[mid]\n",
    "    protinfo = proteins.loc[minfo['TF_ID']]\n",
    "    if type(protinfo['DBD_seqs']) == str:\n",
    "        MotifSequences[mid] = protinfo['DBD_seqs'].split(',')\n",
    "    else:\n",
    "        MotifSequences[mid] = protinfo['DBD_seqs'][0].split(',')\n",
    "    \n",
    "#Get Motifs Sequences that are aligned to common Pfam reference\n",
    "MotifSequences_aligned = {}\n",
    "for mid, unaligned in MotifSequences.items():\n",
    "    MotifSequences_aligned[mid] = [DBDseqs.get(x) for x in unaligned]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make DBD alignments and positional features for motif pairs with E-score overlaps\n",
    "\n",
    "- The MotifAlignments contain the features, and outputs necessary to output into dataframes for training in R. \n",
    "- They can also be scored using existing SR models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Homeodomain_ReplicateThreshold = 0.5555555\n",
    "\n",
    "MotifAlignments = {} # MID Pair : {Alignment Information}\n",
    "\n",
    "for pair, overlap in EScoreOverlaps.items():\n",
    "    #Get Reference alignments for each motif\n",
    "    proteinseqs_x = (pair[0], MotifSequences_aligned[pair[0]])\n",
    "    proteinseqs_y = (pair[1], MotifSequences_aligned[pair[1]])\n",
    "    #Align each motif to eachother\n",
    "    sr_alignment = pwsaln.AlignDBDArrays(proteinseqs_x, proteinseqs_y)\n",
    "    #Add E-score overlap to the alignment information\n",
    "    sr_alignment['EScoreOverlap'] = overlap\n",
    "    sr_alignment['EClass'] = int(overlap >= Homeodomain_ReplicateThreshold)\n",
    "    MotifAlignments[pair] = sr_alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of information in an SR alignment \n",
    "Example: \n",
    "\n",
    "M1009_1.02:Berger08:Hoxa7_2668 vs. M1072_1.02:Badis09:Hoxa3_2783"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_alignment = MotifAlignments[('M1009_1.02', 'M1072_1.02')]\n",
    "\n",
    "print 'Motif Similarity (E-score Overlap):', sr_alignment['EScoreOverlap']\n",
    "print 'Alignment % Amino Acid Identity:', '{:.3f}'.format(100*sr_alignment['PctID_L']) + '%'\n",
    "print 'Positional Amino Acid Identity:', sr_alignment['ByPos.PctID']\n",
    "print 'Positional Amino Acid Similarity:', sr_alignment['ByPos.AvgB62']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the SR Alignment dictionary to make SR training data (A), or score TF pairs using existing models (B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (A) Example of writing the SR alignment dictionary to files/directories for model training with the Rscript (SimilarityRegression_Train.R)\n",
    "\n",
    "This is a  streamlined function to output the training data necessary for the Rscript. The code in \"`Create DBD alignments and training dataframes.ipynb`\" further parses heldout data, and can also handle constructs that are exempt from testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateSRTrainingFrames(motifalignments, loc_OutputFiles = 'sr_out/'):\n",
    "        #Set up lists of Motif IDs. These are used to make the leave-one-out CV folds\n",
    "        uIDs = set()\n",
    "        IDs = []\n",
    "        count = 0\n",
    "    \n",
    "        #Open Outputs (and make folders if necessary)\n",
    "        if os.path.isdir(loc_OutputFiles) == False:\n",
    "            os.mkdir(loc_OutputFiles)\n",
    "        loc_OutputFiles += '/TrainingData/'\n",
    "        if os.path.isdir(loc_OutputFiles) == False:\n",
    "            os.mkdir(loc_OutputFiles)\n",
    "\n",
    "        Y_Sims_PctID = gzip.open(loc_OutputFiles + 'Y_Sims_PctID.csv.gz', 'w')\n",
    "        X_PctID = gzip.open(loc_OutputFiles + 'X_PctID.csv.gz','w')\n",
    "        X_AvgB62 = gzip.open(loc_OutputFiles + 'X_AvgB62.csv.gz', 'w')\n",
    "        X_PctID_Smooth3 = gzip.open(loc_OutputFiles + 'X_PctID_Smooth3.csv.gz', 'w')\n",
    "        X_AvgB62_Smooth3 = gzip.open(loc_OutputFiles + 'X_AvgB62_Smooth3.csv.gz', 'w')\n",
    "        \n",
    "        for ID, aln in motifalignments.items():\n",
    "            if pd.isnull(aln['EScoreOverlap']) == False:\n",
    "                count += 1 #ID passed QC/Inclusion criteria \n",
    "                IDs.append(ID)\n",
    "                uIDs.add(ID[0])\n",
    "                uIDs.add(ID[1])\n",
    "                \n",
    "                #1) Parse the Y-info\n",
    "                if count == 1:\n",
    "                    h = ['MID_x', 'MID_y', 'EScoreOverlap', 'EClass','PctID_L', 'PctID_S', 'ArrayLenDifference', 'MultiAlnFlag']\n",
    "                    Y_Sims_PctID.write(','.join(h) + '\\n')\n",
    "                oline = list(ID) \n",
    "                for col in ['EScoreOverlap', 'EClass','PctID_L', 'PctID_S', 'ArrayLenDifference', 'MultiAlnFlag']:\n",
    "                    oline.append(aln[col])\n",
    "                Y_Sims_PctID.write(','.join(map(str, oline)) + '\\n')\n",
    "\n",
    "                #2) Parse the X matrices\n",
    "                for filehandle, dictID in zip([X_PctID, X_AvgB62, X_PctID_Smooth3, X_AvgB62_Smooth3], \n",
    "                                          ['ByPos.PctID', 'ByPos.AvgB62', 'ByPos.PctID.Smooth3', 'ByPos.AvgB62.Smooth3']):\n",
    "                    if count == 1:\n",
    "                        h = ['MID_x', 'MID_y'] + ['p' + str(x + 1) for x in range(len(aln['ByPos.PctID']))]\n",
    "                        filehandle.write(','.join(h) + '\\n')\n",
    "                    oline = list(ID) + map(str, aln[dictID])\n",
    "                    filehandle.write(','.join(oline) + '\\n')\n",
    "                    \n",
    "        #Close Files\n",
    "        for x in [X_PctID, X_AvgB62, X_PctID_Smooth3, X_AvgB62_Smooth3, Y_Sims_PctID]:\n",
    "            x.close()\n",
    "\n",
    "        #Calculate Testing folds\n",
    "        with open(loc_OutputFiles + 'CVTestIndicies_i0.txt', 'w') as outf:\n",
    "            for uID in uIDs:\n",
    "                present_0 = []\n",
    "                for i, ID in enumerate(IDs):\n",
    "                    present_0.append(i)\n",
    "                oline = [uID] + present_0\n",
    "                outf.write('\\t'.join(map(str, oline)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CreateSRTrainingFrames(motifalignments= MotifAlignments, loc_OutputFiles='Example_HDTrainingFrames/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (B) Example of Scoring TF pairs using an existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read SR Model\n",
    "HD_SRModel = srpred.ReadSRModel('../SRModels/F223_1.97d.json')\n",
    "\n",
    "SR_Scores_i = []\n",
    "SR_Scores = []\n",
    "\n",
    "#Score Motif Alignments\n",
    "for pair, sr_alignment in MotifAlignments.items():\n",
    "    SR_Score, SR_Class = srpred.ScoreAlignmentResult(resultDict=sr_alignment, scoreDict=HD_SRModel)\n",
    "    SR_Scores_i.append(pair)\n",
    "    SR_Scores.append([sr_alignment['PctID_L'], sr_alignment['EScoreOverlap'], SR_Score, SR_Class])\n",
    "SR_Scores = pd.DataFrame(SR_Scores, columns = ['AA %ID','EScoreOverlap', 'SR_Score', 'SR_Class'])\n",
    "SR_Scores.index = pd.MultiIndex.from_tuples(SR_Scores_i)\n",
    "#Derive true TF Similarity Labels (Class)\n",
    "SR_Scores['Class'] = 'Amb'\n",
    "SR_Scores.loc[SR_Scores['EScoreOverlap'] >= Homeodomain_ReplicateThreshold, 'Class'] = 'HSim'\n",
    "SR_Scores.loc[SR_Scores['EScoreOverlap'] < 0.2, 'Class'] = 'Dis'\n",
    "SR_Scores.sort_values('SR_Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
